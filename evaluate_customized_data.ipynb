{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "os.environ['BNB_CUDA_VERSION'] = '118' # need to use Cuda 11.8\n",
    "os.environ['LD_LIBRARY_PATH']= '/usr/local/cuda-11/lib64' # path to your cuda-11 lib64\n",
    "\n",
    "# import required modules:\n",
    "\n",
    "# from exp.exp_model import Exp_Model\n",
    "from data_load.dataloader import DataLoader\n",
    "from explain_module.util import summarize_trial, remove_reflections, save_results#, save_agents\n",
    "from explain_module.agents import PredictReflectAgent\n",
    "from predict_module.merge_peft_adapter import merge_peft_adapter\n",
    "from predict_module.supervised_finetune import supervised_finetune\n",
    "from predict_module.train_reward_model import train_reward_model\n",
    "from predict_module.tuning_lm_with_rl import tuning_lm_with_rl\n",
    "from transformers import LlamaTokenizer, pipeline #, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from trl import AutoModelForCausalLMWithValueHead\n",
    "import os, json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter your openai api key\n",
    "os.environ[\"OPENAI_API_KEY\"] = 'enter_your_openai_api_key_here' # for openai api_key in 'tenacity'\n",
    "\n",
    "# set the random seed (you set your own seed)\n",
    "fix_seed = 100\n",
    "random.seed(fix_seed)\n",
    "torch.manual_seed(fix_seed)\n",
    "np.random.seed(fix_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(price_dir='data/price/preprocessed/', tweet_dir='data/tweet/raw/', seq_len=5, wandb=False, data_path='./data/merge_sample.json', output_path='./saved_models/lora-Vicuna', model_path='lmsys/vicuna-7b-v1.5-16k', eval_steps=200, save_steps=200, resume_from_supervised_checkpoint=None, ignore_data_skip='False', num_reflect_trials=2, datasets_dir='./datasets/', local_rank=0, resume_from_reward_checkpoint=False, deepspeed=None, per_device_train_batch_size=1, per_device_eval_batch_size=1, reward_gradient_accumulation_steps=32, reward_learning_rate=2e-05, weight_decay=0.001, reward_base_model='lmsys/vicuna-7b-v1.5-16k', bf16=False, num_train_epochs=1, train_subset=100000, eval_subset=50000, gradient_checkpointing=False, optim='adamw_hf', lr_scheduler_type='linear', reward_adapter='./saved_models/reward_model_vicuna-7b', rl_base_model='./saved_models/lora-Vicuna-adapter-merged', tokenizer_name='lmsys/vicuna-7b-v1.5-16k', reward_model_name='./saved_models/reward_model_vicuna-7b-adapter-merged', log_with=None, rl_learning_rate=1.4e-05, output_max_length=128, mini_batch_size=1, batch_size=1, ppo_epochs=20, rl_gradient_accumulation_steps=1, adafactor=True, early_stopping=True, target_kl=0.1, reward_baseline=0, batched_gen=True, save_freq=None, output_dir='./saved_models/tuning_llama_rl_checkpoints/', seed=0, num_shots=4, save_dir='results/')\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='generating')\n",
    "\n",
    "# load data\n",
    "parser.add_argument(\"--price_dir\", type=str, default=\"data/price/preprocessed/\")\n",
    "parser.add_argument(\"--tweet_dir\", type=str, default=\"data/tweet/raw/\")\n",
    "parser.add_argument(\"--seq_len\", type=int, default=5)\n",
    "\n",
    "# supervised finetuning\n",
    "parser.add_argument(\"--wandb\", action=\"store_true\", default=False)\n",
    "parser.add_argument(\"--data_path\", type=str, default=\"./data/merge_sample.json\")\n",
    "parser.add_argument(\"--output_path\", type=str, default=\"./saved_models/lora-Vicuna\")\n",
    "parser.add_argument(\"--model_path\", type=str, default=\"lmsys/vicuna-7b-v1.5-16k\")   \n",
    "parser.add_argument(\"--eval_steps\", type=int, default=200)\n",
    "parser.add_argument(\"--save_steps\", type=int, default=200)\n",
    "parser.add_argument(\"--resume_from_supervised_checkpoint\", type=str, default=None)\n",
    "parser.add_argument(\"--ignore_data_skip\", type=str, default=\"False\")\n",
    "\n",
    "# training reward model\n",
    "parser.add_argument(\"--num_reflect_trials\", type=int, default=2)\n",
    "parser.add_argument(\"--datasets_dir\", type=str, default=\"./datasets/\")\n",
    "parser.add_argument('--local_rank', type=int, default=0, help=\"Used for multi-gpu\")\n",
    "parser.add_argument('--resume_from_reward_checkpoint', type=bool, default=False, help=\"If you want to resume training where it left off.\")\n",
    "parser.add_argument('--deepspeed', type=str, default=None, help=\"Path to deepspeed config if using deepspeed. You may need this if the model that you want to train doesn't fit on a single GPU.\")\n",
    "parser.add_argument('--per_device_train_batch_size', type=int, default=1)\n",
    "parser.add_argument('--per_device_eval_batch_size', type=int, default=1)\n",
    "parser.add_argument('--reward_gradient_accumulation_steps', type=int, default=32)\n",
    "parser.add_argument('--reward_learning_rate', type=float, default=2e-5)\n",
    "parser.add_argument('--weight_decay', type=int, default=0.001)\n",
    "parser.add_argument('--reward_base_model', type=str, default=\"lmsys/vicuna-7b-v1.5-16k\", help=\"The model that you want to train from the Hugging Face hub. E.g. gpt2, gpt2-xl, bert, etc.\")\n",
    "parser.add_argument('--bf16', type=bool, default=False, help=\"This essentially cuts the training time in half if you want to sacrifice a little precision and have a supported GPU.\")\n",
    "parser.add_argument('--num_train_epochs', type=int, default=1, help=\"The number of training epochs for the reward model.\")\n",
    "parser.add_argument('--train_subset', type=int, default=100000, help=\"The size of the subset of the training data to use\")\n",
    "parser.add_argument('--eval_subset', type=int, default=50000, help=\"The size of the subset of the eval data to use\")\n",
    "parser.add_argument('--gradient_checkpointing', type=bool, default=False, help=\"Enables gradient checkpointing.\")\n",
    "parser.add_argument('--optim', type=str, default=\"adamw_hf\", help=\"Enables gradient checkpointing.\")\n",
    "parser.add_argument('--lr_scheduler_type', type=str, default=\"linear\", help=\"The lr scheduler\")\n",
    "parser.add_argument('--reward_adapter', type=str, default=\"./saved_models/reward_model_vicuna-7b\")\n",
    "\n",
    "# reinforcement learning\n",
    "parser.add_argument('--rl_base_model', type=str, default=\"./saved_models/lora-Vicuna-adapter-merged\", help=\"the model name\")\n",
    "parser.add_argument('--tokenizer_name', type=str, default=\"lmsys/vicuna-7b-v1.5-16k\", help=\"the tokenizer name\")\n",
    "parser.add_argument('--reward_model_name', type=str, default=\"./saved_models/reward_model_vicuna-7b-adapter-merged\", help=\"the reward model name\")\n",
    "parser.add_argument('--log_with', type=str, default=None, help=\"use 'wandb' to log with wandb\")\n",
    "parser.add_argument('--rl_learning_rate', type=float, default=1.4e-5, help=\"the learning rate\")\n",
    "parser.add_argument('--output_max_length', type=int, default=128, help=\"maximum length for generation\")\n",
    "parser.add_argument('--mini_batch_size', type=int, default=1, help=\"the PPO minibatch size\")\n",
    "parser.add_argument('--batch_size', type=int, default=1, help=\"the batch size\")\n",
    "parser.add_argument('--ppo_epochs', type=int, default=4, help=\"the number of ppo epochs\")\n",
    "parser.add_argument('--rl_gradient_accumulation_steps', type=int, default=1, help=\"the number of gradient accumulation steps\")\n",
    "parser.add_argument('--adafactor', type=bool, default=False, help=\"whether to use the adafactor optimizer\")\n",
    "parser.add_argument('--early_stopping', type=bool, default=True, help=\"whether to early stop\")\n",
    "parser.add_argument('--target_kl', type=float, default=0.1, help=\"kl target for early stopping\")\n",
    "parser.add_argument('--reward_baseline', type=float, default=0, help=\"a baseline value that is subtracted from the reward\")\n",
    "parser.add_argument('--batched_gen', type=bool, default=True, help=\"whether to use the batched text gen\")\n",
    "parser.add_argument('--save_freq', type=int, default=None, help=\"n steps to save the model\")\n",
    "parser.add_argument('--output_dir', type=str, default=\"./saved_models/tuning_llama_rl_checkpoints/\", help=\"directory to save the model\")\n",
    "parser.add_argument('--seed', type=int, default=0, help=\"the seed\")\n",
    "\n",
    "# for evaluation\n",
    "parser.add_argument(\"--num_shots\", type=int, default=4)\n",
    "parser.add_argument(\"--save_dir\", type=str, default=\"results/\")\n",
    "\n",
    "llama_model_path=\"lmsys/vicuna-7b-v1.5-16k\" # 'Llama_models/vicuna-7b-v1.5-16k' # \"lmsys/vicuna-7b-v1.5-16k\"\n",
    "args = parser.parse_args(args=[\n",
    "    '--model_path',llama_model_path,\n",
    "    '--reward_base_model',llama_model_path,\n",
    "    '--tokenizer_name',llama_model_path,\n",
    "    '--price_dir',\"data/price/preprocessed/\", # \"data/sample_price/preprocessed/\",\n",
    "    '--tweet_dir',\"data/tweet/raw/\", # \"data/sample_tweet/raw/\",\n",
    "    '--adafactor',\"True\",\n",
    "    '--ppo_epochs','20',\n",
    "    '--output_max_length','128',\n",
    "    ])\n",
    "print('Args in experiment:')\n",
    "print(args)\n",
    "\n",
    "dataloader = DataLoader(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Test Agents.\n"
     ]
    }
   ],
   "source": [
    "data = dataloader.load(flag=\"test\")\n",
    "\n",
    "agent_cls = PredictReflectAgent\n",
    "test_agents = [agent_cls(row['ticker'], row['summary'], row['target']) for _, row in data.iterrows()]\n",
    "print(\"Loaded Test Agents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abac934ef6ea4a41a4c52244070515e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47066da9438a45108dc8930b99fff7ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at ./saved_models/reward_model_vicuna-7b-adapter-merged and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLMWithValueHead.from_pretrained(\n",
    "    \"./saved_models/sep_model\",\n",
    "    load_in_4bit=True,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = LlamaTokenizer.from_pretrained(args.output_dir+\"final\")#(args.output_dir+\"step_saved\")\n",
    "reward_model = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=args.reward_model_name,\n",
    "    device_map=\"auto\",\n",
    "    model_kwargs={\"load_in_4bit\": True},\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Facts:\n",
      "2025-07-15\n",
      "- Analysts have raised the price target for NVDA to $192, with some predicting the stock could reach $200.\n",
      "- Huawei has introduced a new AI compute platform, challenging Nvidia in the AI space.\n",
      "- There are mixed opinions on NVDA stock, with some analysts giving permission to sell shares while others name it a top pick ahead of earnings.\n",
      "- Analysts and experts believe NVDA will have a good quarter and see long-term upside potential, especially with AI exports to China.\n",
      "- Dan Niles recently turned bullish on Nvidia, while Needham maintains a buy rating and lifted its target to $200.\n",
      "- The stock is predicted to perform well in the tech sector, along with AMD and INTC.\n",
      "- NVDA's market cap is surging, and the company is leading in AI technology.\n",
      "- Some sources provide long-term stock price predictions for NVDA, projecting where the stock could be by 2025, 2026, and 2030.\n",
      "\n",
      "Price Movement: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yc_yam/anaconda3/envs/sep/lib/python3.10/site-packages/transformers/generation/utils.py:1539: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
      "  warnings.warn(\n",
      "/home/yc_yam/anaconda3/envs/sep/lib/python3.10/site-packages/bitsandbytes/nn/modules.py:226: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n",
      "  warnings.warn(f'Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n",
      "\n",
      "Explanation: Recent market analysis, opinions, and predictions have generated a positive price movement outlook for NVDA stock. Analysts and experts maintain a bullish stance, expecting a good quarter ahead and long-term upside potential. The strong positioning of NVDA in AI technology and its market cap surge reflect the company's growth trajectory. With some analysts raising the price target for NVDA to $192 and $200, and others giving a green light to buy shares, the market sentiment is optimistic. The tech sector, including NVDA, AMD, and INTC, is predicted to perform well, contributing to the positive Price Movement. The mixed opinions on selling shares while others name the stock a top pick ahead of earnings demonstrate the market's confidence in NVDA's future prospects. While there are long-term stock price predictions for NVDA, this analysis indicates a positive Price Movement in the short term, driven by the company's strong market position, evolving industry trends, and favorable market predictions.\n",
      "\n",
      "\n",
      "\n",
      "Finished evaluation, Correct: 1, Incorrect: 0\n"
     ]
    }
   ],
   "source": [
    "# This part using OPENAI inference will cost money!!\n",
    "\n",
    "for agent in test_agents:\n",
    "    agent.run_n_shots(\n",
    "                        model=model,\n",
    "                        tokenizer=tokenizer,\n",
    "                        reward_model=reward_model,\n",
    "                        num_shots=args.num_shots\n",
    "                        )\n",
    "\n",
    "correct, incorrect = summarize_trial(test_agents)\n",
    "print(f'Finished evaluation, Correct: {len(correct)}, Incorrect: {len(incorrect)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference results saved at 'results/'\n"
     ]
    }
   ],
   "source": [
    "save_results(test_agents, args.save_dir)\n",
    "print('Inference results saved at \\'{}\\''.format(args.save_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
